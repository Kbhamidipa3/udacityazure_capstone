{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNwiQxsz1IQd"
   },
   "source": [
    "**Automated ML**\n",
    "\n",
    "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "DMcCv4bM04fR",
    "outputId": "8230bd43-5b2a-4dfc-9759-cc11b70bc964"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: inference-schema==1.1.0 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (1.1.0)\n",
      "Requirement already satisfied: wrapt==1.11.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from inference-schema==1.1.0) (1.11.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from inference-schema==1.1.0) (2020.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from inference-schema==1.1.0) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from python-dateutil>=2.5.3->inference-schema==1.1.0) (1.15.0)\n",
      "SDK version: 1.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip install inference-schema==1.1.0\n",
    "import logging\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import pkg_resources\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.core import Workspace,ScriptRunConfig,Experiment, Run\n",
    "from azureml.pipeline.steps import AutoMLStep\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packages\n",
      "--------\n",
      "# Conda environment specification. The dependencies defined in this file will\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\n",
      "\n",
      "# Details about the Conda environment file format:\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "  - azureml-interpret~=1.19.0\n",
      "  - azureml-train-automl~=1.19.0\n",
      "  - azureml-defaults~=1.19.0\n",
      "- scikit-learn\n",
      "- pandas\n",
      "- numpy\n",
      "- py-xgboost<=0.80\n",
      "channels:\n",
      "- anaconda\n",
      "- conda-forge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.environment import Environment\n",
    "Environment(name=\"myenv\")\n",
    "print(\"packages\")\n",
    "print(\"--------\")       \n",
    "print(myenv.python.conda_dependencies.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRBV9sMs1ETX"
   },
   "source": [
    "**Dataset**\n",
    "\n",
    "***Overview***\n",
    "\n",
    "TODO: In this markdown cell, give an overview of the dataset you are using. Also mention the task you will be performing.\n",
    "\n",
    "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "43zx6FqC1DMH",
    "outputId": "451e2361-fe0c-4030-824f-c884d1183f5c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quick-starts-ws-132176\n",
      "aml-quickstarts-132176\n",
      "southcentralus\n",
      "976ee174-3882-4721-b90a-b5fef6b72f24\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rU4w8tQ1TsF"
   },
   "source": [
    "**Create or Attach an AmlCompute clusterÂ¶**\n",
    "\n",
    "You will need to create a compute target for your AutoML run. In this tutorial, you get the default AmlCompute as your training compute resource.\n",
    "\n",
    "Udacity Note There is no need to create a new compute target, it can re-use the previous cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "YCRP-9Ae1Xvj",
    "outputId": "992b35c3-3333-4780-cd26-558ba25f74ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n",
      "Succeeded....................................................................................................................\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Wait timeout has been reached\n",
      "Current provisioning state of AmlCompute is \"Succeeded\" and current node count is \"0\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# NOTE: update the cluster name to match the existing cluster\n",
    "# Choose a name for your CPU cluster\n",
    "amlcompute_cluster_name = \"automl-cluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',# for GPU, use \"STANDARD_NC6\"\n",
    "                                                           #vm_priority = 'lowpriority', # optional\n",
    "                                                           max_nodes=4)\n",
    "    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True, min_node_count = 1, timeout_in_minutes = 10)\n",
    "# For a more detailed view of current AmlCompute status, use get_status()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ogGpnyip1kXe"
   },
   "source": [
    "**Data**\n",
    "\n",
    "**Udacity note:**\n",
    "\n",
    "Make sure the key is the same name as the dataset that is uploaded, and that the description matches. If it is hard to find or unknown, loop over the ws.datasets.keys() and print() them. If it isn't found because it was deleted, it can be recreated with the link that has the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s7vzLvTO1lXM"
   },
   "outputs": [],
   "source": [
    "# Try to load the dataset from the Workspace. Otherwise, create it from the file\n",
    "# NOTE: update the key to match the dataset name\n",
    "found = False\n",
    "key = \"LV_github_automl\"\n",
    "description_text = \"LV hotel reviews from trip advisor\"\n",
    "\n",
    "if key in ws.datasets.keys(): \n",
    "        found = True\n",
    "        dataset = ws.datasets[key] \n",
    "\n",
    "if not found:\n",
    "        # Create AML Dataset and register it into Workspace\n",
    "        LV_github_automl = 'https://raw.githubusercontent.com/Kbhamidipa3/udacityazure_capstone_final/main/LV_github_automl.csv'\n",
    "        dataset = Dataset.Tabular.from_delimited_files(LV_github_automl)        \n",
    "        #Register Dataset in Workspace\n",
    "        dataset = dataset.register(workspace=ws,\n",
    "                                   name=key,\n",
    "                                   description=description_text)\n",
    "\n",
    "\n",
    "df = dataset.to_pandas_dataframe()\n",
    "#config = ScriptRunConfig(source_directory='training', script='train.py', compute_target='cpu-cluster')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNEdHKEu1o2m"
   },
   "source": [
    "**Review the Dataset Result**\n",
    "\n",
    "You can peek the result of a TabularDataset at any range using skip(i) and take(j).to_pandas_dataframe(). Doing so evaluates only j records for all the steps in the TabularDataset, which makes it fast even against large datasets.\n",
    "\n",
    "TabularDataset objects are composed of a list of transformation steps (optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "TL7AmF-p1-XL",
    "outputId": "fdeee9ad-cfd6-4857-a180-305a323223b4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Casino</th>\n",
       "      <th>Free_internet</th>\n",
       "      <th>Gym</th>\n",
       "      <th>Helpful_votes</th>\n",
       "      <th>Hotel_name</th>\n",
       "      <th>Hotel_stars</th>\n",
       "      <th>Member_years</th>\n",
       "      <th>Nr_hotel_reviews</th>\n",
       "      <th>Nr_reviews</th>\n",
       "      <th>...</th>\n",
       "      <th>Period_of_stay</th>\n",
       "      <th>Pool</th>\n",
       "      <th>Review_month</th>\n",
       "      <th>Review_weekday</th>\n",
       "      <th>Score</th>\n",
       "      <th>Spa</th>\n",
       "      <th>Tennis_court</th>\n",
       "      <th>Traveler_type</th>\n",
       "      <th>User_continent</th>\n",
       "      <th>User_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>Circus Circus Hotel &amp; Casino Las Vegas</td>\n",
       "      <td>3</td>\n",
       "      <td>9.00</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>Dec-Feb</td>\n",
       "      <td>False</td>\n",
       "      <td>January</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Friends</td>\n",
       "      <td>North America</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>75</td>\n",
       "      <td>Circus Circus Hotel &amp; Casino Las Vegas</td>\n",
       "      <td>3</td>\n",
       "      <td>3.00</td>\n",
       "      <td>21</td>\n",
       "      <td>119</td>\n",
       "      <td>...</td>\n",
       "      <td>Dec-Feb</td>\n",
       "      <td>False</td>\n",
       "      <td>January</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Business</td>\n",
       "      <td>North America</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "      <td>Circus Circus Hotel &amp; Casino Las Vegas</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>Mar-May</td>\n",
       "      <td>False</td>\n",
       "      <td>February</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Families</td>\n",
       "      <td>North America</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>Circus Circus Hotel &amp; Casino Las Vegas</td>\n",
       "      <td>3</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>Mar-May</td>\n",
       "      <td>False</td>\n",
       "      <td>February</td>\n",
       "      <td>Friday</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Friends</td>\n",
       "      <td>Europe</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>Circus Circus Hotel &amp; Casino Las Vegas</td>\n",
       "      <td>3</td>\n",
       "      <td>7.00</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>Mar-May</td>\n",
       "      <td>False</td>\n",
       "      <td>March</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Solo</td>\n",
       "      <td>North America</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column1  Casino  Free_internet   Gym  Helpful_votes  \\\n",
       "0        0    True           True  True             13   \n",
       "1        1    True           True  True             75   \n",
       "2        2    True           True  True             25   \n",
       "3        3    True           True  True             14   \n",
       "4        4    True           True  True              2   \n",
       "\n",
       "                               Hotel_name  Hotel_stars  Member_years  \\\n",
       "0  Circus Circus Hotel & Casino Las Vegas            3          9.00   \n",
       "1  Circus Circus Hotel & Casino Las Vegas            3          3.00   \n",
       "2  Circus Circus Hotel & Casino Las Vegas            3          2.00   \n",
       "3  Circus Circus Hotel & Casino Las Vegas            3          6.00   \n",
       "4  Circus Circus Hotel & Casino Las Vegas            3          7.00   \n",
       "\n",
       "   Nr_hotel_reviews  Nr_reviews  ...  Period_of_stay   Pool  Review_month  \\\n",
       "0                 4          11  ...         Dec-Feb  False       January   \n",
       "1                21         119  ...         Dec-Feb  False       January   \n",
       "2                 9          36  ...         Mar-May  False      February   \n",
       "3                 7          14  ...         Mar-May  False      February   \n",
       "4                 5           5  ...         Mar-May  False         March   \n",
       "\n",
       "  Review_weekday Score    Spa  Tennis_court  Traveler_type User_continent  \\\n",
       "0       Thursday     1  False         False        Friends  North America   \n",
       "1         Friday     0  False         False       Business  North America   \n",
       "2       Saturday     1  False         False       Families  North America   \n",
       "3         Friday     1  False         False        Friends         Europe   \n",
       "4        Tuesday     1  False         False           Solo  North America   \n",
       "\n",
       "  User_country  \n",
       "0          USA  \n",
       "1          USA  \n",
       "2          USA  \n",
       "3           UK  \n",
       "4       Canada  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5=dataset.take(5).to_pandas_dataframe()\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejL6DaPQ3skj"
   },
   "source": [
    "**Split into train and test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eaAc9HlC3B1N",
    "outputId": "3a388e6a-766a-47d4-afb9-e8c906688fd1"
   },
   "outputs": [],
   "source": [
    "from train import clean_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    " \n",
    "#x, y = clean_data(ds)\n",
    "train_data, test_data = dataset.random_split(percentage=0.75, seed=223)\n",
    "x_train = train_data.to_pandas_dataframe().pop('Score')\n",
    "y_train = train_data.to_pandas_dataframe().Score\n",
    "x_test = test_data.to_pandas_dataframe().pop('Score')\n",
    "y_test = test_data.to_pandas_dataframe().Score\n",
    "data_train = pd.concat([x_train,y_train], axis=1)\n",
    "\n",
    "os.makedirs('data_train', exist_ok=True)\n",
    "\n",
    "local_path = './data_train/data_train.csv'\n",
    "data_train.to_csv(local_path)\n",
    "\n",
    "# upload the local file to a datastore on the cloud\n",
    "workspace = Workspace(ws.subscription_id, ws.resource_group, ws.name)\n",
    "\n",
    "# get the datastore to upload prepared data\n",
    "datastore = ws.get_default_datastore()\n",
    "\n",
    "# upload the local file from src_dir to the target_path in datastore\n",
    "datastore.upload(src_dir='data_train', target_path='data_train')\n",
    "\n",
    "# create a dataset referencing the cloud location\n",
    "data_train = Dataset.Tabular.from_delimited_files(path = [(datastore, ('data_train/data_train.csv'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yaziKBGT2CCm"
   },
   "source": [
    "**AutoML Configuration**\n",
    "\n",
    "TODO: Explain why you chose the automl settings and cofiguration you used below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "D4oAWjuj2GeT"
   },
   "outputs": [],
   "source": [
    "automl_settings = {\n",
    "    \"experiment_timeout_minutes\": 20,\n",
    "    \"max_concurrent_iterations\": 5,\n",
    "    \"primary_metric\" : 'accuracy'\n",
    "}\n",
    "automl_config = AutoMLConfig(compute_target=compute_target,\n",
    "                             task = \"classification\",\n",
    "                             training_data=dataset,\n",
    "                             label_column_name=\"Score\",   \n",
    "                             enable_early_stopping= True,\n",
    "                             featurization= 'auto',\n",
    "                             debug_log = \"automl_errors.log\",\n",
    "                             **automl_settings\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFf0TOXA4GeW"
   },
   "source": [
    "**Submit your automl run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "A0qZS5T44EQg",
    "outputId": "d70c493f-1671-475c-dcb0-aaf37725f5ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on remote.\n",
      "No run_configuration provided, running on automl-cluster with default configuration\n",
      "Running on remote compute: automl-cluster\n",
      "Parent Run ID: AutoML_b70b1e94-d490-49ef-8929-61912c606b1d\n",
      "\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n",
      "Current status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "DATA GUARDRAILS: \n",
      "\n",
      "TYPE:         Cross validation\n",
      "STATUS:       DONE\n",
      "DESCRIPTION:  Each iteration of the trained model was validated through cross-validation.\n",
      "              \n",
      "DETAILS:      \n",
      "+---------------------------------+\n",
      "|Number of folds                  |\n",
      "+=================================+\n",
      "|10                               |\n",
      "+---------------------------------+\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         Class balancing detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Your inputs were analyzed, and all classes are balanced in your training data.\n",
      "              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         Missing feature values imputation\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  No feature missing values were detected in the training data.\n",
      "              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         High cardinality feature detection\n",
      "STATUS:       DONE\n",
      "DESCRIPTION:  High cardinality features were detected in your inputs and handled.\n",
      "              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n",
      "DETAILS:      High cardinality features refer to columns that contain a large percentage of unique values.\n",
      "+---------------------------------+---------------------------------+\n",
      "|Column name                      |Column Content Type              |\n",
      "+=================================+=================================+\n",
      "|User_country                     |categorical_hash                 |\n",
      "+---------------------------------+---------------------------------+\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         2   MaxAbsScaler RandomForest                      0:00:46       0.7660    0.7660\n",
      "         3   MaxAbsScaler RandomForest                      0:00:50       0.7759    0.7759\n",
      "         4   MaxAbsScaler RandomForest                      0:00:45       0.7260    0.7759\n",
      "         0   MaxAbsScaler LightGBM                          0:00:55       0.7417    0.7759\n",
      "         7   SparseNormalizer XGBoostClassifier             0:00:52       0.7460    0.7759\n",
      "         8   SparseNormalizer XGBoostClassifier             0:00:53       0.7538    0.7759\n",
      "         9   MaxAbsScaler GradientBoosting                  0:00:47       0.7759    0.7759\n",
      "         1   MaxAbsScaler XGBoostClassifier                 0:03:13       0.7540    0.7759\n",
      "         5   MaxAbsScaler RandomForest                      0:03:21       0.6626    0.7759\n",
      "         6   SparseNormalizer XGBoostClassifier             0:03:24       0.7341    0.7759\n",
      "        10   SparseNormalizer LightGBM                      0:00:51       0.7619    0.7759\n",
      "        11   SparseNormalizer XGBoostClassifier             0:00:43       0.7619    0.7759\n",
      "        12   MaxAbsScaler LightGBM                          0:00:49       0.7739    0.7759\n",
      "        13   MaxAbsScaler LogisticRegression                0:00:46       0.7360    0.7759\n",
      "        14   MaxAbsScaler ExtremeRandomTrees                0:00:54       0.7759    0.7759\n",
      "        15   StandardScalerWrapper RandomForest             0:00:47       0.7758    0.7759\n",
      "        16   StandardScalerWrapper LogisticRegression       0:00:42       0.7161    0.7759\n",
      "        17   MaxAbsScaler LogisticRegression                0:00:45       0.7201    0.7759\n",
      "        18   StandardScalerWrapper LightGBM                 0:00:48       0.7719    0.7759\n",
      "        19   SparseNormalizer XGBoostClassifier             0:01:00       0.7678    0.7759\n",
      "        20   MaxAbsScaler LightGBM                          0:00:51       0.7719    0.7759\n",
      "        21   SparseNormalizer LightGBM                      0:00:49       0.7759    0.7759\n",
      "        22   MaxAbsScaler LightGBM                          0:00:40       0.7699    0.7759\n",
      "        23   StandardScalerWrapper LightGBM                 0:00:45       0.7758    0.7759\n",
      "        24   SparseNormalizer XGBoostClassifier             0:00:48       0.7579    0.7759\n",
      "        26   SparseNormalizer LightGBM                      0:00:46       0.7659    0.7759\n",
      "        25   SparseNormalizer RandomForest                  0:00:54       0.7759    0.7759\n",
      "        27   SparseNormalizer LightGBM                      0:00:46       0.7718    0.7759\n",
      "        28   SparseNormalizer XGBoostClassifier             0:00:38       0.7619    0.7759\n",
      "        29   SparseNormalizer LightGBM                      0:00:46       0.7759    0.7759\n",
      "        30   MaxAbsScaler RandomForest                      0:00:57       0.7759    0.7759\n",
      "        31   MaxAbsScaler LightGBM                          0:00:45       0.7756    0.7759\n",
      "        32   SparseNormalizer LightGBM                      0:00:45       0.7639    0.7759\n",
      "        33   SparseNormalizer LightGBM                      0:00:44       0.7679    0.7759\n",
      "        34   StandardScalerWrapper LightGBM                 0:00:31          nan    0.7759\n",
      "        35   StandardScalerWrapper RandomForest             0:00:22          nan    0.7759\n",
      "        36                                                  0:00:15          nan    0.7759\n",
      "        37                                                  0:00:19          nan    0.7759\n",
      "        38    VotingEnsemble                                0:01:40       0.7759    0.7759\n",
      "        39    StackEnsemble                                 0:01:51       0.7759    0.7759\n"
     ]
    }
   ],
   "source": [
    "experiment_name = 'lv-automl-classification'\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "run = experiment.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVm7S0Cf5gaY"
   },
   "source": [
    "Results\n",
    "Widget for Monitoring Runs\n",
    "The widget will first report a \"loading\" status while running the first iteration. After completing the first iteration, an auto-updating graph and table will be shown. The widget will refresh once per minute, so you should see the graph update as child runs complete.\n",
    "\n",
    "Note: The widget displays a link at the bottom. Use this link to open a web interface to explore the individual run details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "c6d25d1f9987405098149b86535a724d"
     ]
    },
    "id": "Ike1GL_15pdE",
    "outputId": "0c054fb9-8af0-4199-86c7-b9a78f888062"
   },
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6Mgb1o_4OZR"
   },
   "source": [
    "**Analyze results**\n",
    "\n",
    "Retrieve the Best Model\n",
    "Below we select the best pipeline from our iterations. The get_output method on automl_classifier returns the best run and the fitted model for the last invocation. Overloads on get_output allow you to retrieve the best run and fitted model for any logged metric or for a particular iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "ayaOLXjy4O7F",
    "outputId": "cef264d3-7802-46f0-e167-0b415dbc129a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: lv-automl-classification,\n",
      "Id: AutoML_b70b1e94-d490-49ef-8929-61912c606b1d_25,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Completed)\n"
     ]
    }
   ],
   "source": [
    "best_run, fitted_model = run.get_output()\n",
    "print(best_run)\n",
    "#print(fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KE7lJDI6AQI"
   },
   "source": [
    "**Tests**\n",
    "\n",
    "Now that the model is trained, split the data in the same way the data was split for training (The difference here is the data is being split locally) and then run the test data through the trained model to get the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J7NePAUs6Ed4"
   },
   "outputs": [],
   "source": [
    "# convert the test data to dataframe\n",
    "X_test_df = test_data.drop_columns('Score').to_pandas_dataframe()\n",
    "Y_test_df = test_data.keep_columns('Score', validate=True).to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GkzH8HHv6c0Q",
    "outputId": "91b7261f-88a4-4b71-f845-d7713f0e01e2"
   },
   "outputs": [],
   "source": [
    "# call the predict functions on the model\n",
    "y_pred = fitted_model.predict(X_test_df)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LHtTWaK6f_P"
   },
   "source": [
    "**Calculate metrics for the prediction**\n",
    "\n",
    "Now visualize the data on a scatter plot to show what our truth (actual) values are compared to the predicted values from the trained model that was returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "YEVPEt2R6jtY",
    "outputId": "b7d12a7a-5726-4488-8948-ce30632b8c8d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "cf =confusion_matrix(Y_test_df.values,y_pred)\n",
    "plt.imshow(cf,cmap=plt.cm.Blues,interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "class_labels = ['False','True']\n",
    "tick_marks = np.arange(len(class_labels))\n",
    "plt.xticks(tick_marks,class_labels)\n",
    "plt.yticks([-0.5,0,1,1.5],['','False','True',''])\n",
    "# plotting text value inside cells\n",
    "thresh = cf.max() / 2.\n",
    "for i,j in itertools.product(range(cf.shape[0]),range(cf.shape[1])):\n",
    "    plt.text(j,i,format(cf[i,j],'d'),horizontalalignment='center',color='white' if cf[i,j] >thresh else 'black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQZlrP9H7JGx"
   },
   "source": [
    "**Retrieve any other AutoML model from training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "OxR5IT5-7LUs"
   },
   "outputs": [],
   "source": [
    "best_run, fitted_model = run.get_output(metric='accuracy')\n",
    "ensemble_run, fitted_model = run.get_output(metric='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCkRyAGQ7eGx"
   },
   "source": [
    "**Setup the model explanations for AutoML models**\n",
    "\n",
    "The fitted_model can generate the following which will be used for getting the engineered explanations using automl_setup_model_explanations:-\n",
    "\n",
    "Featurized data from train samples/test samples\n",
    "Gather engineered name lists\n",
    "Find the classes in your labeled column in classification scenarios\n",
    "The automl_explainer_setup_obj contains all the structures from above list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "rb8TPM4T7gw6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabularDataset\n",
      "{\n",
      "  \"source\": [\n",
      "    \"https://raw.githubusercontent.com/Kbhamidipa3/udacityazure_capstone_final/main/LV_github_automl.csv\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetFiles\",\n",
      "    \"ParseDelimited\",\n",
      "    \"DropColumns\",\n",
      "    \"SetColumnTypes\",\n",
      "    \"RandomSplit\",\n",
      "    \"KeepColumns\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "X_train = train_data.drop_columns('Score')\n",
    "y_train = train_data.keep_columns('Score', validate=True)\n",
    "X_test = test_data.drop_columns('Score')\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "hm6kUwjq7kq4",
    "outputId": "a0c0a5c5-160b-462b-e672-84198d240dd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current status: Setting up data for AutoML explanations\n",
      "Current status: Setting up the AutoML featurizer\n",
      "Current status: Setting up the AutoML estimator\n",
      "Current status: Setting up the AutoML featurization for explanations\n",
      "Current status: Using 120 evaluation samples\n",
      "Current status: Generating a feature map for raw feature importance\n",
      "Current status: Finding all classes from the dataset\n",
      "Current status: Choosing the surrogate model as LightGBM for the AutoML model\n",
      "Current status: Data for AutoML explanations successfully setup\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.automl.runtime.automl_explain_utilities import automl_setup_model_explanations\n",
    "\n",
    "automl_explainer_setup_obj = automl_setup_model_explanations(fitted_model, X=X_train, \n",
    "                                                             X_test=X_test, y=y_train, \n",
    "                                                             task='classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GdO6qFFN8I7H"
   },
   "source": [
    "**Initialize the Mimic Explainer for feature importance**\n",
    "\n",
    "For explaining the AutoML models, use the MimicWrapper from azureml-interpret package. The MimicWrapper can be initialized with fields in automl_explainer_setup_obj, your workspace and a surrogate model to explain the AutoML model (fitted_model here). The MimicWrapper also takes the automl_run object where engineered explanations will be uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "QIh02E1O8NaH"
   },
   "outputs": [],
   "source": [
    "from interpret.ext.glassbox import LGBMExplainableModel\n",
    "from azureml.interpret.mimic_wrapper import MimicWrapper\n",
    "explainer = MimicWrapper(ws, automl_explainer_setup_obj.automl_estimator,\n",
    "                         explainable_model=automl_explainer_setup_obj.surrogate_model, \n",
    "                         init_dataset=automl_explainer_setup_obj.X_transform, run=best_run,\n",
    "                         features=automl_explainer_setup_obj.engineered_feature_names, \n",
    "                         feature_maps=[automl_explainer_setup_obj.feature_map],\n",
    "                         classes=automl_explainer_setup_obj.classes,\n",
    "                         explainer_kwargs=automl_explainer_setup_obj.surrogate_model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgseHnEx8T6X"
   },
   "source": [
    "**Use Mimic Explainer for computing and visualizing engineered feature importance**\n",
    "\n",
    "The explain() method in MimicWrapper can be called with the transformed test samples to get the feature importance for the generated engineered features. You can also use azure portal url to view the dash board visualization of the feature importance values of the engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "6lFGepbf8ZP3",
    "outputId": "133335a2-e581-46e0-e41e-06822caec179"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'User_country_HashOneHotEncoder_31': 0.0, 'Pool_ModeCatImputer_LabelEncoder': 0.0, 'Hotel_name_CharGramCountVectorizer_tuscany las vegas suites & casino': 0.0, 'Hotel_name_CharGramCountVectorizer_wyndham grand desert': 0.0, 'Hotel_name_CharGramCountVectorizer_wynn las vegas': 0.0, 'Hotel_stars_CharGramCountVectorizer_3': 0.0, 'Hotel_stars_CharGramCountVectorizer_4': 0.0, 'Hotel_stars_CharGramCountVectorizer_5': 0.0, 'Period_of_stay_CharGramCountVectorizer_dec-feb': 0.0, 'Period_of_stay_CharGramCountVectorizer_jun-aug': 0.0, 'Period_of_stay_CharGramCountVectorizer_mar-may': 0.0, 'Period_of_stay_CharGramCountVectorizer_sep-nov': 0.0, 'Review_month_CharGramCountVectorizer_april': 0.0, 'Hotel_name_CharGramCountVectorizer_tropicana las vegas - a double tree by hilton hotel': 0.0, 'Review_month_CharGramCountVectorizer_august': 0.0, 'Review_month_CharGramCountVectorizer_december': 0.0, 'Review_month_CharGramCountVectorizer_february': 0.0, 'Review_month_CharGramCountVectorizer_january': 0.0, 'Review_month_CharGramCountVectorizer_july': 0.0, 'Review_month_CharGramCountVectorizer_june': 0.0, 'Review_month_CharGramCountVectorizer_march': 0.0, 'Review_month_CharGramCountVectorizer_may': 0.0, 'Review_month_CharGramCountVectorizer_november': 0.0, 'Review_month_CharGramCountVectorizer_october': 0.0, 'Hotel_name_CharGramCountVectorizer_trump international hotel las vegas': 0.0, 'Hotel_name_CharGramCountVectorizer_treasure island- ti hotel & casino': 0.0, 'User_country_HashOneHotEncoder_30': 0.0, 'Hotel_name_CharGramCountVectorizer_circus circus hotel & casino las vegas': 0.0, 'Helpful_votes_MeanImputer': 0.0, 'Member_years_MeanImputer': 0.0, 'Nr_hotel_reviews_MeanImputer': 0.0, 'Nr_reviews_MeanImputer': 0.0, 'Nr_rooms_MeanImputer': 0.0, 'Casino_ModeCatImputer_LabelEncoder': 0.0, 'Free_internet_ModeCatImputer_LabelEncoder': 0.0, 'Gym_ModeCatImputer_LabelEncoder': 0.0, 'Hotel_name_CharGramCountVectorizer_bellagio las vegas': 0.0, 'Hotel_name_CharGramCountVectorizer_caesars palace': 0.0, 'Hotel_name_CharGramCountVectorizer_encore at wynn las vegas': 0.0, 'Hotel_name_CharGramCountVectorizer_the westin las vegas hotel casino & spa': 0.0, 'Hotel_name_CharGramCountVectorizer_excalibur hotel & casino': 0.0, 'Hotel_name_CharGramCountVectorizer_hilton grand vacations at the flamingo': 0.0, 'Hotel_name_CharGramCountVectorizer_hilton grand vacations on the boulevard': 0.0, \"Hotel_name_CharGramCountVectorizer_marriott's grand chateau\": 0.0, 'Hotel_name_CharGramCountVectorizer_monte carlo resort&casino': 0.0, 'Hotel_name_CharGramCountVectorizer_paris las vegas': 0.0, 'Hotel_name_CharGramCountVectorizer_the cosmopolitan las vegas': 0.0, 'Hotel_name_CharGramCountVectorizer_the cromwell': 0.0, 'Hotel_name_CharGramCountVectorizer_the palazzo resort hotel casino': 0.0, 'Hotel_name_CharGramCountVectorizer_the venetian las vegas hotel': 0.0, 'Review_month_CharGramCountVectorizer_september': 0.0, 'Review_weekday_CharGramCountVectorizer_friday': 0.0, 'Review_weekday_CharGramCountVectorizer_monday': 0.0, 'User_country_HashOneHotEncoder_18': 0.0, 'User_country_HashOneHotEncoder_8': 0.0, 'User_country_HashOneHotEncoder_9': 0.0, 'User_country_HashOneHotEncoder_10': 0.0, 'User_country_HashOneHotEncoder_11': 0.0, 'User_country_HashOneHotEncoder_12': 0.0, 'User_country_HashOneHotEncoder_13': 0.0, 'User_country_HashOneHotEncoder_14': 0.0, 'User_country_HashOneHotEncoder_15': 0.0, 'User_country_HashOneHotEncoder_16': 0.0, 'User_country_HashOneHotEncoder_17': 0.0, 'User_country_HashOneHotEncoder_19': 0.0, 'Review_weekday_CharGramCountVectorizer_saturday': 0.0, 'User_country_HashOneHotEncoder_20': 0.0, 'User_country_HashOneHotEncoder_21': 0.0, 'User_country_HashOneHotEncoder_22': 0.0, 'User_country_HashOneHotEncoder_23': 0.0, 'User_country_HashOneHotEncoder_24': 0.0, 'User_country_HashOneHotEncoder_25': 0.0, 'User_country_HashOneHotEncoder_26': 0.0, 'User_country_HashOneHotEncoder_27': 0.0, 'User_country_HashOneHotEncoder_28': 0.0, 'User_country_HashOneHotEncoder_29': 0.0, 'User_country_HashOneHotEncoder_7': 0.0, 'User_country_HashOneHotEncoder_6': 0.0, 'User_country_HashOneHotEncoder_5': 0.0, 'User_country_HashOneHotEncoder_4': 0.0, 'Review_weekday_CharGramCountVectorizer_sunday': 0.0, 'Review_weekday_CharGramCountVectorizer_thursday': 0.0, 'Review_weekday_CharGramCountVectorizer_tuesday': 0.0, 'Review_weekday_CharGramCountVectorizer_wednesday': 0.0, 'Spa_ModeCatImputer_LabelEncoder': 0.0, 'Tennis_court_ModeCatImputer_LabelEncoder': 0.0, 'Traveler_type_CharGramCountVectorizer_business': 0.0, 'Traveler_type_CharGramCountVectorizer_couples': 0.0, 'Traveler_type_CharGramCountVectorizer_families': 0.0, 'Traveler_type_CharGramCountVectorizer_friends': 0.0, 'Traveler_type_CharGramCountVectorizer_solo': 0.0, 'User_continent_CharGramCountVectorizer_africa': 0.0, 'User_continent_CharGramCountVectorizer_asia': 0.0, 'User_continent_CharGramCountVectorizer_europe': 0.0, 'User_continent_CharGramCountVectorizer_north america': 0.0, 'User_continent_CharGramCountVectorizer_oceania': 0.0, 'User_continent_CharGramCountVectorizer_south america': 0.0, 'User_country_HashOneHotEncoder_0': 0.0, 'User_country_HashOneHotEncoder_1': 0.0, 'User_country_HashOneHotEncoder_2': 0.0, 'User_country_HashOneHotEncoder_3': 0.0, 'Column1_MeanImputer': 0.0}\n",
      "You can visualize the engineered explanations under the 'Explanations (preview)' tab in the AutoML run at:-\n",
      "https://ml.azure.com/experiments/lv-automl-classification/runs/AutoML_b70b1e94-d490-49ef-8929-61912c606b1d_25?wsid=/subscriptions/976ee174-3882-4721-b90a-b5fef6b72f24/resourcegroups/aml-quickstarts-132176/workspaces/quick-starts-ws-132176\n"
     ]
    }
   ],
   "source": [
    "# Compute the engineered explanations\n",
    "engineered_explanations = explainer.explain(['local', 'global'], eval_dataset=automl_explainer_setup_obj.X_test_transform)\n",
    "print(engineered_explanations.get_feature_importance_dict())\n",
    "print(\"You can visualize the engineered explanations under the 'Explanations (preview)' tab in the AutoML run at:-\\n\" + best_run.get_portal_url())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOFkPVia8eg0"
   },
   "source": [
    "**Use Mimic Explainer for computing and visualizing raw feature importance**\n",
    "\n",
    "The explain() method in MimicWrapper can be called with the transformed test samples to get the feature importance for the original features in your data. You can also use azure portal url to view the dash board visualization of the feature importance values of the original/raw features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "PVpMicFy8mHW",
    "outputId": "9db736d1-d5a8-4aea-ad88-d6cde7b27ee1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'User_country': 0.0, 'User_continent': 0.0, 'Casino': 0.0, 'Free_internet': 0.0, 'Gym': 0.0, 'Helpful_votes': 0.0, 'Hotel_name': 0.0, 'Hotel_stars': 0.0, 'Member_years': 0.0, 'Nr_hotel_reviews': 0.0, 'Nr_reviews': 0.0, 'Nr_rooms': 0.0, 'Period_of_stay': 0.0, 'Pool': 0.0, 'Review_month': 0.0, 'Review_weekday': 0.0, 'Spa': 0.0, 'Tennis_court': 0.0, 'Traveler_type': 0.0, 'Column1': 0.0}\n",
      "You can visualize the raw explanations under the 'Explanations (preview)' tab in the AutoML run at:-\n",
      "https://ml.azure.com/experiments/lv-automl-classification/runs/AutoML_b70b1e94-d490-49ef-8929-61912c606b1d_25?wsid=/subscriptions/976ee174-3882-4721-b90a-b5fef6b72f24/resourcegroups/aml-quickstarts-132176/workspaces/quick-starts-ws-132176\n"
     ]
    }
   ],
   "source": [
    "# Compute the raw explanations\n",
    "raw_explanations = explainer.explain(['local', 'global'], get_raw=True,\n",
    "                                     raw_feature_names=automl_explainer_setup_obj.raw_feature_names,\n",
    "                                     eval_dataset=automl_explainer_setup_obj.X_test_transform,\n",
    "                                     raw_eval_dataset=automl_explainer_setup_obj.X_test_raw)\n",
    "print(raw_explanations.get_feature_importance_dict())\n",
    "print(\"You can visualize the raw explanations under the 'Explanations (preview)' tab in the AutoML run at:-\\n\" + best_run.get_portal_url())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CoRVRw9P8n02"
   },
   "source": [
    "**Initialize the scoring Explainer, save and upload it for later use in scoring explanation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "C31ztX008s86"
   },
   "outputs": [],
   "source": [
    "from azureml.interpret.scoring.scoring_explainer import TreeScoringExplainer\n",
    "import joblib\n",
    "\n",
    "# Initialize the ScoringExplainer\n",
    "scoring_explainer = TreeScoringExplainer(explainer.explainer, feature_maps=[automl_explainer_setup_obj.feature_map])\n",
    "\n",
    "# Pickle scoring explainer locally to './scoring_explainer.pkl'\n",
    "scoring_explainer_file_name = 'scoring_explainer.pkl'\n",
    "with open(scoring_explainer_file_name, 'wb') as stream:\n",
    "    joblib.dump(scoring_explainer, stream)\n",
    "\n",
    "# Register trained automl model present in the 'outputs' folder in the artifacts\n",
    "#original_model = run.register_model(model_name='lv-automl-classification',model_path='outputs/model.pkl')\n",
    "    \n",
    "original_model = best_run.register_model(model_name='lv-automl-classification',model_path='outputs/model.pkl')\n",
    "\n",
    "# Upload the scoring explainer to the automl run\n",
    "#best_run.upload_file('outputs/scoring_explainer.pkl', scoring_explainer_file_name)\n",
    "scoring_explainer_model = best_run.register_model(model_name='scoring_explainer', model_path='outputs/scoring_explainer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVO-goYF-AAe"
   },
   "source": [
    "**Create the conda dependencies for setting up the service**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "7aGkwlXC-Bgj",
    "outputId": "eb232f55-9104-40ac-b35d-7683c50938ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Conda environment specification. The dependencies defined in this file will\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\n",
      "\n",
      "# Details about the Conda environment file format:\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "  - azureml-interpret~=1.19.0\n",
      "  - azureml-train-automl~=1.19.0\n",
      "  - azureml-defaults~=1.19.0\n",
      "- scikit-learn\n",
      "- pandas\n",
      "- numpy\n",
      "- py-xgboost<=0.80\n",
      "channels:\n",
      "- anaconda\n",
      "- conda-forge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "azureml_pip_packages = [\n",
    "    'azureml-interpret', 'azureml-train-automl', 'azureml-defaults'\n",
    "]\n",
    "\n",
    "myenv = CondaDependencies.create(conda_packages=['scikit-learn', 'pandas', 'numpy', 'py-xgboost<=0.80'],\n",
    "                                 pip_packages=azureml_pip_packages,\n",
    "                                 pin_sdk_version=True)\n",
    "\n",
    "with open(\"myenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "\n",
    "with open(\"myenv.yml\",\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the environment inside a Docker container.\n",
    "myenv.docker.enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "XHxwkIA6nJKs",
    "outputId": "94558ba5-d376-4228-911c-64de32b3c3d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs/model.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = os.getcwd()\n",
    "os.listdir(path)\n",
    "path\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "model_path = Model.get_model_path(model_name='outputs/model.pkl')\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxklb5ZD-Dv3"
   },
   "source": [
    "**Deploy the service**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "yqoIOtvLHvnQ",
    "outputId": "ac26c445-2d2b-46bc-81d2-8fc25f6c5681"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model scoring_explainer:4 to /tmp/azureml_5sykflur/scoring_explainer/4\n",
      "Downloading model lv-automl-classification:9 to /tmp/azureml_5sykflur/lv-automl-classification/9\n",
      "Generating Docker build context.\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry 989135cb6e0e49d8b9ed601665539ff9.azurecr.io\n",
      "Logging into Docker registry 989135cb6e0e49d8b9ed601665539ff9.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM 989135cb6e0e49d8b9ed601665539ff9.azurecr.io/azureml/azureml_41868f9a2ccda6649509c1df4048b13e\n",
      " ---> 80b2bfc7101c\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> 9f6ab0a75e4d\n",
      "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6Ijk3NmVlMTc0LTM4ODItNDcyMS1iOTBhLWI1ZmVmNmI3MmYyNCIsInJlc291cmNlR3JvdXBOYW1lIjoiYW1sLXF1aWNrc3RhcnRzLTEzMjE3NiIsImFjY291bnROYW1lIjoicXVpY2stc3RhcnRzLXdzLTEzMjE3NiIsIndvcmtzcGFjZUlkIjoiOTg5MTM1Y2ItNmUwZS00OWQ4LWI5ZWQtNjAxNjY1NTM5ZmY5In0sIm1vZGVscyI6e30sIm1vZGVsc0luZm8iOnt9fQ== | base64 --decode > /var/azureml-app/model_config_map.json\n",
      " ---> Running in 4d2bd7aaa74c\n",
      " ---> f35d7ab92572\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmpt5x_mkhj.py' /var/azureml-app/main.py\n",
      " ---> Running in 98de64bd43ce\n",
      " ---> f9732474a4b1\n",
      "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
      " ---> Running in 9b68f3b5fa59\n",
      " ---> 52c50578cf00\n",
      "Successfully built 52c50578cf00\n",
      "Successfully tagged model1-score:latest\n",
      "Container (name:pedantic_bouman, id:8fa98a49864605c4e8945b2f02eb0410d91cb4c9e95b6964efe7b9cef6668810) cannot be killed.\n",
      "Container has been successfully cleaned up.\n",
      "Image sha256:ad81fd8e132adce51ca736222d6ed021c3c1875385fe5796b21ca432d5865be6 successfully removed.\n",
      "Starting Docker container...\n",
      "Docker container running.\n",
      "Checking container health...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:azureml._model_management._util:Error: Container has crashed. Did your init method fail?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Container Logs:\n",
      "2020-12-28T18:14:58,696884551+00:00 - rsyslog/run \n",
      "2020-12-28T18:14:58,698739835+00:00 - iot-server/run \n",
      "2020-12-28T18:14:58,699958625+00:00 - gunicorn/run \n",
      "2020-12-28T18:14:58,709351747+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_c48771bbe5fa224df5d541af81b23025/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_c48771bbe5fa224df5d541af81b23025/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_c48771bbe5fa224df5d541af81b23025/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_c48771bbe5fa224df5d541af81b23025/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_c48771bbe5fa224df5d541af81b23025/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2020-12-28T18:14:58,784287221+00:00 - iot-server/finish 1 0\n",
      "2020-12-28T18:14:58,785546910+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (11)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 42\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Exception in worker process\n",
      "Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_c48771bbe5fa224df5d541af81b23025/lib/python3.6/site-packages/gunicorn/arbiter.py\", line 583, in spawn_worker\n",
      "    worker.init_process()\n",
      "  File \"/azureml-envs/azureml_c48771bbe5fa224df5d541af81b23025/lib/python3.6/site-packages/gunicorn/workers/base.py\", line 129, in init_process\n",
      "    self.load_wsgi()\n",
      "  File \"/azureml-envs/azureml_c48771bbe5fa224df5d541af81b23025/lib/python3.6/site-packages/gunicorn/workers/base.py\", line 138, in load_wsgi\n",
      "    self.wsgi = self.app.wsgi()\n",
      "  File \"/azureml-envs/azureml_c48771bbe5fa224df5d541af81b23025/lib/python3.6/site-packages/gunicorn/app/base.py\", line 67, in wsgi\n",
      "    self.callable = self.load()\n",
      "  File \"/azureml-envs/azureml_c48771bbe5fa224df5d541af81b23025/lib/python3.6/site-packages/gunicorn/app/wsgiapp.py\", line 52, in load\n",
      "    return self.load_wsgiapp()\n",
      "  File \"/azureml-envs/azureml_c48771bbe5fa224df5d541af81b23025/lib/python3.6/site-packages/gunicorn/app/wsgiapp.py\", line 41, in load_wsgiapp\n",
      "    return util.import_app(self.app_uri)\n",
      "  File \"/azureml-envs/azureml_c48771bbe5fa224df5d541af81b23025/lib/python3.6/site-packages/gunicorn/util.py\", line 350, in import_app\n",
      "    __import__(module)\n",
      "  File \"/var/azureml-server/wsgi.py\", line 1, in <module>\n",
      "    import create_app\n",
      "  File \"/var/azureml-server/create_app.py\", line 3, in <module>\n",
      "    from app import main\n",
      "  File \"/var/azureml-server/app.py\", line 32, in <module>\n",
      "    from aml_blueprint import AMLBlueprint\n",
      "  File \"/var/azureml-server/aml_blueprint.py\", line 23, in <module>\n",
      "    main_module_spec.loader.exec_module(main)\n",
      "  File \"/var/azureml-app/score_automl.py\", line 16, in <module>\n",
      "    from inference_schema.schema_decorators import input_schema, output_schema\n",
      "ModuleNotFoundError: No module named 'inference_schema'\n",
      "Worker exiting (pid: 42)\n",
      "Shutting down: Master\n",
      "Reason: Worker failed to boot.\n",
      "2020-12-28T18:15:00,217420245+00:00 - gunicorn/finish 3 0\n",
      "2020-12-28T18:15:00,218699434+00:00 - Exit code 3 is not normal. Killing image.\n",
      "\n"
     ]
    },
    {
     "ename": "WebserviceException",
     "evalue": "WebserviceException:\n\tMessage: Error: Container has crashed. Did your init method fail?\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Error: Container has crashed. Did your init method fail?\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-e428748e5260>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Use configs and models generated above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0maci_service\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'model1-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscoring_explainer_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moriginal_model\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minference_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdeployment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0maci_service\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_deployment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0maci_service\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregen_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Primary\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# or\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/local.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 raise WebserviceException('Cannot call {}() when service is {}.'.format(func.__name__, self.state),\n\u001b[1;32m     71\u001b[0m                                           logger=module_logger)\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/local.py\u001b[0m in \u001b[0;36mwait_for_deployment\u001b[0;34m(self, show_output)\u001b[0m\n\u001b[1;32m    609\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m                                    \u001b[0mhealth_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_health_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m                                    cleanup_if_failed=False)\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocalWebservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTATE_RUNNING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_model_management/_util.py\u001b[0m in \u001b[0;36mcontainer_health_check\u001b[0;34m(docker_port, container, health_url, cleanup_if_failed)\u001b[0m\n\u001b[1;32m    741\u001b[0m             \u001b[0;31m# The container has started and crashed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             _raise_for_container_failure(container, cleanup_if_failed,\n\u001b[0;32m--> 743\u001b[0;31m                                          'Error: Container has crashed. Did your init method fail?')\n\u001b[0m\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;31m# The container hasn't crashed, so try to ping the health endpoint.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_model_management/_util.py\u001b[0m in \u001b[0;36m_raise_for_container_failure\u001b[0;34m(container, cleanup, message)\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0mcleanup_container\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1261\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mWebserviceException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodule_logger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Error: Container has crashed. Did your init method fail?\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Error: Container has crashed. Did your init method fail?\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.webservice import AciWebservice, LocalWebservice\n",
    "from azureml.core.model import Model, InferenceConfig\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "#aciconfig = AciWebservice.deploy_configuration(cpu_cores=1.8,\n",
    "                                               #memory_gb=4,\n",
    "                                               #auth_enabled=True,\n",
    "                                               #enable_app_insights=True\n",
    "                                               #)\n",
    "\n",
    "deployment_config = LocalWebservice.deploy_configuration(port=8890)\n",
    "myenv = Environment.from_conda_specification(name=\"myenv\", file_path=\"myenv.yml\")\n",
    "inference_config = InferenceConfig(entry_script='score_automl.py', environment=myenv)\n",
    "\n",
    "# Use configs and models generated above\n",
    "aci_service = Model.deploy(ws,'model1-score',[scoring_explainer_model,original_model],inference_config,deployment_config)\n",
    "aci_service.wait_for_deployment(show_output=True)\n",
    "aci_service.regen_key(\"Primary\")\n",
    "# or\n",
    "aci_service.regen_key(\"Secondary\")\n",
    "print(aci_service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddbCXV7QIA2w"
   },
   "source": [
    "**View the service logs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "yxkOakJ2I6F3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-28T18:08:39,304758366+00:00 - rsyslog/run \n",
      "2020-12-28T18:08:39,310089122+00:00 - gunicorn/run \n",
      "2020-12-28T18:08:39,310857916+00:00 - iot-server/run \n",
      "2020-12-28T18:08:39,320155340+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_c48771bbe5fa224df5d541af81b23025/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_c48771bbe5fa224df5d541af81b23025/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_c48771bbe5fa224df5d541af81b23025/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_c48771bbe5fa224df5d541af81b23025/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_c48771bbe5fa224df5d541af81b23025/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2020-12-28T18:08:39,395805719+00:00 - iot-server/finish 1 0\n",
      "2020-12-28T18:08:39,397329206+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (10)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 41\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Exception in worker process\n",
      "Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_c48771bbe5fa224df5d541af81b23025/lib/python3.6/site-packages/gunicorn/arbiter.py\", line 583, in spawn_worker\n",
      "    worker.init_process()\n",
      "  File \"/azureml-envs/azureml_c48771bbe5fa224df5d541af81b23025/lib/python3.6/site-packages/gunicorn/workers/base.py\", line 129, in init_process\n",
      "    self.load_wsgi()\n",
      "  File \"/azureml-envs/azureml_c48771bbe5fa224df5d541af81b23025/lib/python3.6/site-packages/gunicorn/workers/base.py\", line 138, in load_wsgi\n",
      "    self.wsgi = self.app.wsgi()\n",
      "  File \"/azureml-envs/azureml_c48771bbe5fa224df5d541af81b23025/lib/python3.6/site-packages/gunicorn/app/base.py\", line 67, in wsgi\n",
      "    self.callable = self.load()\n",
      "  File \"/azureml-envs/azureml_c48771bbe5fa224df5d541af81b23025/lib/python3.6/site-packages/gunicorn/app/wsgiapp.py\", line 52, in load\n",
      "    return self.load_wsgiapp()\n",
      "  File \"/azureml-envs/azureml_c48771bbe5fa224df5d541af81b23025/lib/python3.6/site-packages/gunicorn/app/wsgiapp.py\", line 41, in load_wsgiapp\n",
      "    return util.import_app(self.app_uri)\n",
      "  File \"/azureml-envs/azureml_c48771bbe5fa224df5d541af81b23025/lib/python3.6/site-packages/gunicorn/util.py\", line 350, in import_app\n",
      "    __import__(module)\n",
      "  File \"/var/azureml-server/wsgi.py\", line 1, in <module>\n",
      "    import create_app\n",
      "  File \"/var/azureml-server/create_app.py\", line 3, in <module>\n",
      "    from app import main\n",
      "  File \"/var/azureml-server/app.py\", line 32, in <module>\n",
      "    from aml_blueprint import AMLBlueprint\n",
      "  File \"/var/azureml-server/aml_blueprint.py\", line 23, in <module>\n",
      "    main_module_spec.loader.exec_module(main)\n",
      "  File \"/var/azureml-app/score_automl.py\", line 16, in <module>\n",
      "    from inference_schema.schema_decorators import input_schema, output_schema\n",
      "ModuleNotFoundError: No module named 'inference_schema'\n",
      "Worker exiting (pid: 41)\n",
      "Shutting down: Master\n",
      "Reason: Worker failed to boot.\n",
      "2020-12-28T18:08:40,837922182+00:00 - gunicorn/finish 3 0\n",
      "2020-12-28T18:08:40,839185071+00:00 - Exit code 3 is not normal. Killing image.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(aci_service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vj2gflNVH6Oh"
   },
   "source": [
    "**Inference with test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ucn5YGRUH982"
   },
   "outputs": [],
   "source": [
    "if aci_service.state == 'Healthy':\n",
    "    # Serialize the first row of the test data into json\n",
    "    X_test_json = X_test[:1].to_json(orient='records')\n",
    "    print(X_test_json)\n",
    "    # Call the service to get the predictions and the engineered explanations\n",
    "    output = aci_service.run(X_test_json)\n",
    "    # Print the predicted value\n",
    "    print(output['predictions'])\n",
    "    # Print the engineered feature importances for the predicted value\n",
    "    print(output['engineered_local_importance_values'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6tTIUDdsO2d"
   },
   "source": [
    "**Retrieve the Best ONNX Model**\n",
    "\n",
    "Below we select the best pipeline from our iterations. The get_output method returns the best run and the fitted model. The Model includes the pipeline and any pre-processing. Overloads on get_output allow you to retrieve the best run and fitted model for any logged metric or for a particular iteration.\n",
    "\n",
    "Set the parameter return_onnx_model=True to retrieve the best ONNX model, instead of the Python model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rubcy69EsVLd"
   },
   "outputs": [],
   "source": [
    "best_run, onnx_mdl = remote_run.get_output(return_onnx_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCWKvdj4sg5n"
   },
   "source": [
    "**Save the best ONNX model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "onQYYbQZsjgU"
   },
   "outputs": [],
   "source": [
    "from azureml.automl.runtime.onnx_convert import OnnxConverter\n",
    "onnx_fl_path = \"./best_model.onnx\"\n",
    "OnnxConverter.save_onnx_model(onnx_mdl, onnx_fl_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEXEbXzbJLh_"
   },
   "source": [
    "**Delete the service.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R1uXmUpOJNET"
   },
   "outputs": [],
   "source": [
    "#service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_J3kcdv84ae6"
   },
   "source": [
    "**Delete the cluster at the end of the run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vL71J_4z4ZN_"
   },
   "outputs": [],
   "source": [
    "#cpu_cluster.delete()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of automl.ipynb",
   "provenance": [
    {
     "file_id": "1sGB6HmIcIhG95w8ao7zzAi3VoIh5rXRC",
     "timestamp": 1609126336835
    }
   ]
  },
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
